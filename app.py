import streamlit as st
import os
import tempfile
import subprocess
import json
import time
import datetime
import io
from pathlib import Path
from typing import List, Dict, Any, Optional
import logging
from openai import OpenAI
import docx
from docx.shared import Pt, Inches
from docx.enum.text import WD_ALIGN_PARAGRAPH

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Page configuration
st.set_page_config(
    page_title="–°–∏—Å—Ç–µ–º–∞ –ø–æ–º–æ—â–Ω–∏–∫–∞ —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è",
    page_icon="üîç",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS
def load_css():
    st.markdown("""
        <style>
        /* Main styles */
        .stApp {
            background-color: #F3F4F6;
        }
        
        /* Cards */
        .card {
            padding: 1.5rem;
            border-radius: 0.5rem;
            background-color: white;
            box-shadow: 0 1px 3px rgba(0,0,0,0.1);
            margin-bottom: 1rem;
        }
        
        .card-header {
            font-weight: bold;
            font-size: 1.2rem;
            margin-bottom: 1rem;
            padding-bottom: 0.5rem;
            border-bottom: 1px solid #e5e7eb;
        }
        
        /* Buttons */
        .primary-btn {
            background-color: #1E40AF;
            color: white;
            padding: 0.5rem 1rem;
            border-radius: 0.375rem;
            border: none;
            cursor: pointer;
            font-weight: 500;
            width: 100%;
        }
        
        .primary-btn:hover {
            background-color: #1E3A8A;
        }
        
        /* Form elements */
        .form-input {
            padding: 0.5rem;
            border: 1px solid #D1D5DB;
            border-radius: 0.375rem;
            width: 100%;
            margin-bottom: 0.5rem;
        }
        
        /* Tables */
        .styled-table {
            width: 100%;
            border-collapse: collapse;
        }
        
        .styled-table th, .styled-table td {
            padding: 0.75rem;
            text-align: left;
            border-bottom: 1px solid #e5e7eb;
        }
        
        .styled-table th {
            background-color: #f9fafb;
            font-weight: 500;
        }
        
        .footer {
            text-align: center;
            padding: 1rem;
            color: #6B7280;
            font-size: 0.875rem;
            margin-top: 2rem;
        }
        </style>
    """, unsafe_allow_html=True)

# Initialize OpenAI client
def init_openai():
    api_key = st.secrets.get("openai_api_key")
    if not api_key:
        st.error("API –∫–ª—é—á OpenAI –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –¥–æ–±–∞–≤—å—Ç–µ –µ–≥–æ –≤ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ —Å–µ–∫—Ä–µ—Ç–æ–≤.")
        return None
    
    try:
        return OpenAI(api_key=api_key)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏ OpenAI API: {str(e)}")
        return None

# Create necessary directories
def create_directories():
    try:
        Path("storage/transcriptions").mkdir(parents=True, exist_ok=True)
        Path("storage/planning").mkdir(parents=True, exist_ok=True)
        Path("storage/indictments").mkdir(parents=True, exist_ok=True)
        Path("storage/methodologies").mkdir(parents=True, exist_ok=True)
        Path("storage/evidence").mkdir(parents=True, exist_ok=True)
        Path("storage/temp").mkdir(parents=True, exist_ok=True)
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–π: {str(e)}")

# Check for FFmpeg availability
def check_ffmpeg():
    try:
        subprocess.run(["ffmpeg", "-version"], check=True, capture_output=True)
        return True
    except (subprocess.CalledProcessError, FileNotFoundError):
        return False

# Generate unique case number
def generate_case_number(prefix="–ú"):
    now = datetime.datetime.now()
    return f"{prefix}-{now.strftime('%Y%m%d-%H%M%S')}"

# Save session history
def save_history(module_type, data):
    """Save history data to the appropriate directory"""
    create_directories()
    
    filename = f"{module_type}_{data.get('id', datetime.datetime.now().strftime('%Y%m%d%H%M%S'))}.json"
    filepath = f"storage/{module_type}/{filename}"
    
    with open(filepath, "w", encoding="utf-8") as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    return filepath

# Load session history
def load_history(module_type):
    """Load all history data from the specified module directory"""
    history_path = f"storage/{module_type}"
    if not os.path.exists(history_path):
        return []
    
    history_files = [f for f in os.listdir(history_path) if f.endswith('.json')]
    history = []
    
    for file in history_files:
        try:
            with open(os.path.join(history_path, file), "r", encoding="utf-8") as f:
                history.append(json.load(f))
        except Exception as e:
            logger.error(f"Error loading history file {file}: {str(e)}")
    
    # Sort by date (newest first)
    return sorted(history, key=lambda x: x.get('generatedDate', ''), reverse=True)

def create_docx_document(title, content_sections, metadata=None):
    """
    Creates a DOCX document with the given title, content sections, and metadata.
    
    Args:
        title (str): Document title
        content_sections (list): List of dictionaries with 'heading' and 'content' keys
        metadata (dict, optional): Document metadata (case number, date, etc.)
    
    Returns:
        BytesIO: Document as bytes stream
    """
    doc = docx.Document()
    
    # Set document margins (1 inch on all sides)
    sections = doc.sections
    for section in sections:
        section.top_margin = Inches(1)
        section.bottom_margin = Inches(1)
        section.left_margin = Inches(1)
        section.right_margin = Inches(1)
    
    # Add title
    title_paragraph = doc.add_paragraph()
    title_run = title_paragraph.add_run(title)
    title_run.bold = True
    title_run.font.size = Pt(16)
    title_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
    
    # Add metadata if provided
    if metadata:
        metadata_paragraph = doc.add_paragraph()
        metadata_paragraph.alignment = WD_ALIGN_PARAGRAPH.CENTER
        for key, value in metadata.items():
            if value:
                metadata_paragraph.add_run(f"{key}: {value}\n")
        
        # Add spacing after metadata
        doc.add_paragraph()
    
    # Add content sections
    for section in content_sections:
        if section.get('heading'):
            heading = doc.add_heading(section['heading'], level=2)
            heading.alignment = WD_ALIGN_PARAGRAPH.LEFT
        
        if section.get('content'):
            content = section['content']
            
            # Handle content based on type
            if isinstance(content, list):
                # If content is a list, create bullet points
                for item in content:
                    p = doc.add_paragraph(style='List Bullet')
                    p.add_run(item)
            else:
                # Plain text content
                paragraphs = content.split('\n')
                for para in paragraphs:
                    if para.strip():
                        p = doc.add_paragraph()
                        p.add_run(para)
    
    # Save document to memory stream
    docx_bytes = io.BytesIO()
    doc.save(docx_bytes)
    docx_bytes.seek(0)
    
    return docx_bytes

#############################
# Transcription Module Code #
#############################

def extract_audio(uploaded_file):
    """Extract audio from video file or process audio file directly"""
    input_path = None 
    try:
        if uploaded_file.name.lower().endswith(('.mp4', '.avi', '.mov')):
            if not check_ffmpeg():
                st.error("FFmpeg –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω...")
                return None
        with tempfile.NamedTemporaryFile(delete=False, suffix=os.path.splitext(uploaded_file.name)[1]) as tmpfile:
            tmpfile.write(uploaded_file.getbuffer())
            input_path = tmpfile.name
        if uploaded_file.name.lower().endswith(('.mp4', '.avi', '.mov')):
            audio_path = os.path.splitext(input_path)[0] + '.mp3'
            subprocess.run(["ffmpeg", "-i", input_path, "-q:a", "0", "-map", "a", audio_path], check=True, capture_output=True)
            if input_path and os.path.exists(input_path):
                 os.remove(input_path) # –£–¥–∞–ª—è–µ–º –≤–∏–¥–µ–æ
            return audio_path # –í–æ–∑–≤—Ä–∞—â–∞–µ–º mp3
        else:
            return input_path # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –∞—É–¥–∏–æ
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∏–∑–≤–ª–µ—á–µ–Ω–∏–∏ –∞—É–¥–∏–æ: {str(e)}")
        if input_path and os.path.exists(input_path): 
            os.remove(input_path) # –£–¥–∞–ª—è–µ–º –ø—Ä–∏ –æ—à–∏–±–∫–µ
        return None # –í–æ–∑–≤—Ä–∞—â–∞–µ–º None

def transcribe_audio(client, audio_file, language='ru'):
    """Transcribe audio file using OpenAI Whisper"""
    try:
        with open(audio_file, "rb") as file:
            transcript = client.audio.transcriptions.create(
                model="whisper-1",
                file=file,
                language=language
            )
        return transcript.text
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏: {str(e)}")
        return None
    finally:
        if os.path.exists(audio_file):
            os.remove(audio_file)

def analyze_transcription(client, text, analysis_type, language='ru'):
    """Analyze transcription text based on specified analysis type"""
    # System prompts based on analysis type
    prompts = {
        "summary": f"–í—ã –æ–ø—ã—Ç–Ω—ã–π —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å. –°—É–º–º–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–π —Ç–µ–∫—Å—Ç –ø–æ–∫–∞–∑–∞–Ω–∏–π –Ω–∞ —è–∑—ã–∫–µ {language}, –≤—ã–¥–µ–ª–∏–≤ –∫–ª—é—á–µ–≤—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é:",
        "sequence": "–í—ã —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å, –æ—Ü–µ–Ω–∏–≤–∞—é—â–∏–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏–π. –ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Ç–µ–∫—Å—Ç –∏ –≤—ã—è–≤–∏—Ç–µ –Ω–∞—Ä—É—à–µ–Ω–∏—è –ª–æ–≥–∏—á–µ—Å–∫–æ–π –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ –∏–ª–∏ –ø—Ä–æ–ø—É—â–µ–Ω–Ω—ã–µ –¥–µ—Ç–∞–ª–∏:",
        "facts": "–í—ã —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å, –≤—ã–¥–µ–ª—è—é—â–∏–π —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã. –ò–∑–≤–ª–µ–∫–∏—Ç–µ –∏–∑ —Ç–µ–∫—Å—Ç–∞ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã, –∏–º–µ—é—â–∏–µ –∑–Ω–∞—á–µ–Ω–∏–µ –¥–ª—è —Å–ª–µ–¥—Å—Ç–≤–∏—è, –≤ –≤–∏–¥–µ —Å–ø–∏—Å–∫–∞:",
    }
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": prompts.get(analysis_type, prompts["summary"])},
                {"role": "user", "content": text}
            ],
            temperature=0.5,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ: {str(e)}")
        return None

def compare_testimonies(client, text1, text2):
    """Compare two testimonies to find contradictions and extract relevant quotes.
    Returns a list of dictionaries, each representing a contradiction.
    """
    prompt = (
        "–í—ã —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å, —Å–æ–ø–æ—Å—Ç–∞–≤–ª—è—é—â–∏–π –ø–æ–∫–∞–∑–∞–Ω–∏—è –¥–ª—è –≤—ã—è–≤–ª–µ–Ω–∏—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π. "
        "–°—Ä–∞–≤–Ω–∏—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –¥–≤–∞ –ø–æ–∫–∞–∑–∞–Ω–∏—è –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ —Å—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –º–µ–∂–¥—É –Ω–∏–º–∏. "
        "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –Ω–∞–π–¥–µ–Ω–Ω–æ–≥–æ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –ø—Ä–µ–¥–æ—Å—Ç–∞–≤—å—Ç–µ:\n"
        "1. –ö—Ä–∞—Ç–∫–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å—É—Ç–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è.\n"
        "2. –¢–æ—á–Ω—É—é —Ü–∏—Ç–∞—Ç—É –∏–∑ –ø–æ–∫–∞–∑–∞–Ω–∏–π –õ–∏—Ü–∞ ‚Ññ1, –∏–ª–ª—é—Å—Ç—Ä–∏—Ä—É—é—â—É—é —ç—Ç–æ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ.\n"
        "3. –¢–æ—á–Ω—É—é —Ü–∏—Ç–∞—Ç—É –∏–∑ –ø–æ–∫–∞–∑–∞–Ω–∏–π –õ–∏—Ü–∞ ‚Ññ2, –∏–ª–ª—é—Å—Ç—Ä–∏—Ä—É—é—â—É—é —ç—Ç–æ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–µ.\n"
        "4. –û—Ü–µ–Ω–∫—É –∑–Ω–∞—á–∏–º–æ—Å—Ç–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è (–Ω–∞–ø—Ä–∏–º–µ—Ä, –ù–∏–∑–∫–∞—è, –°—Ä–µ–¥–Ω—è—è, –í—ã—Å–æ–∫–∞—è).\n\n"
        "–û—Ç–≤–µ—Ç –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å –ø—Ä–µ–¥—Å—Ç–∞–≤–ª–µ–Ω –°–¢–†–û–ì–û –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON —Å–ø–∏—Å–∫–∞ –æ–±—ä–µ–∫—Ç–æ–≤, –≥–¥–µ –∫–∞–∂–¥—ã–π –æ–±—ä–µ–∫—Ç –∏–º–µ–µ—Ç –∫–ª—é—á–∏: "
        "'description' (—Å—Ç—Ä–æ–∫–∞), 'quote1' (—Å—Ç—Ä–æ–∫–∞), 'quote2' (—Å—Ç—Ä–æ–∫–∞), 'significance' (—Å—Ç—Ä–æ–∫–∞).\n"
        "–ü—Ä–∏–º–µ—Ä –æ–±—ä–µ–∫—Ç–∞ JSON:\n"
        "{\n"
        "  \"description\": \"–í—Ä–µ–º—è —É—Ö–æ–¥–∞ –∏–∑ –¥–æ–º–∞\",\n"
        "  \"quote1\": \"–Ø —É—à–µ–ª –∏–∑ –¥–æ–º–∞ –æ–∫–æ–ª–æ 9 —É—Ç—Ä–∞.\",\n"
        "  \"quote2\": \"–û–Ω –≤—ã—à–µ–ª –Ω–µ —Ä–∞–Ω—å—à–µ 11 —á–∞—Å–æ–≤.\",\n"
        "  \"significance\": \"–°—Ä–µ–¥–Ω—è—è\"\n"
        "}\n\n"
        "–ï—Å–ª–∏ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π –Ω–µ –Ω–∞–π–¥–µ–Ω–æ, –≤–µ—Ä–Ω–∏—Ç–µ –ø—É—Å—Ç–æ–π JSON —Å–ø–∏—Å–æ–∫ [].\n\n"
        "–ü–æ–∫–∞–∑–∞–Ω–∏—è –ª–∏—Ü–∞ ‚Ññ1:\n" + text1 + "\n\n"
        "–ü–æ–∫–∞–∑–∞–Ω–∏—è –ª–∏—Ü–∞ ‚Ññ2:\n" + text2
    )
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–í—ã –æ–ø—ã—Ç–Ω—ã–π —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å, —Ç–æ—á–Ω–æ –∏–∑–≤–ª–µ–∫–∞—é—â–∏–π –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –∏ —Ü–∏—Ç–∞—Ç—ã –∏–∑ –ø–æ–∫–∞–∑–∞–Ω–∏–π –≤ —Ñ–æ—Ä–º–∞—Ç–µ JSON."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={ "type": "json_object"} 
        )
        raw_response = response.choices[0].message.content.strip()
        try:
            contradictions_list = json.loads(raw_response)
            if isinstance(contradictions_list, list):
                return contradictions_list
            else:
                 if isinstance(contradictions_list, dict):
                     for key, value in contradictions_list.items():
                         if isinstance(value, list):
                             st.warning(f"–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ JSON-–æ–±—ä–µ–∫—Ç –≤–º–µ—Å—Ç–æ —Å–ø–∏—Å–∫–∞. –ò—Å–ø–æ–ª—å–∑—É—é —Å–ø–∏—Å–æ–∫ –∏–∑ –∫–ª—é—á–∞ '{key}'.")
                             return value
                 st.error("–ú–æ–¥–µ–ª—å –≤–µ—Ä–Ω—É–ª–∞ –∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π JSON, –Ω–æ –Ω–µ –≤ —Ñ–æ—Ä–º–∞—Ç–µ —Å–ø–∏—Å–∫–∞.")
                 print(f"–ù–µ–æ–∂–∏–¥–∞–Ω–Ω—ã–π JSON –æ—Ç OpenAI: {raw_response}")
                 return [] 
        except json.JSONDecodeError as json_e:
            st.error(f"–û—à–∏–±–∫–∞ –¥–µ–∫–æ–¥–∏—Ä–æ–≤–∞–Ω–∏—è JSON –æ—Ç–≤–µ—Ç–∞ –æ—Ç OpenAI: {json_e}")
            st.warning("–ú–æ–¥–µ–ª—å –Ω–µ –≤–µ—Ä–Ω—É–ª–∞ –≤–∞–ª–∏–¥–Ω—ã–π JSON. –ü—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è –Ω–µ –±—É–¥—É—Ç –∏–∑–≤–ª–µ—á–µ–Ω—ã.")
            print(f"–ù–µ–≤–∞–ª–∏–¥–Ω—ã–π JSON –æ—Ç OpenAI: {raw_response}")
            return [] 
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å—Ä–∞–≤–Ω–µ–Ω–∏–∏ –ø–æ–∫–∞–∑–∞–Ω–∏–π: {str(e)}")
        return None 

def generate_questions(client, contradictions):
    """Generate questions based on contradictions"""
    prompt = (
        "–ù–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π, –≤—ã—è–≤–ª–µ–Ω–Ω—ã—Ö –≤ –ø–æ–∫–∞–∑–∞–Ω–∏—è—Ö, —Å—Ñ–æ—Ä–º—É–ª–∏—Ä—É–π—Ç–µ —Å–ø–∏—Å–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã—Ö –≤–æ–ø—Ä–æ—Å–æ–≤ –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏—è "
        "–∏ —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π:\n\n" + contradictions
    )
    
    try:
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–í—ã –æ–ø—ã—Ç–Ω—ã–π —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å, —Ñ–æ—Ä–º—É–ª–∏—Ä—É—é—â–∏–π —Ç–æ—á–Ω—ã–µ –≤–æ–ø—Ä–æ—Å—ã –¥–ª—è —É—Å—Ç—Ä–∞–Ω–µ–Ω–∏—è –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π –≤ –ø–æ–∫–∞–∑–∞–Ω–∏—è—Ö."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
        )
        result = response.choices[0].message.content.strip()
        
        # Ensure result is in list format
        if not result.startswith("1.") and not result.startswith("-"):
            lines = result.split("\n")
            formatted_result = ""
            for i, line in enumerate(lines, 1):
                if line.strip():
                    formatted_result += f"{i}. {line.strip()}\n"
            return formatted_result
        
        return result
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –≤–æ–ø—Ä–æ—Å–æ–≤: {str(e)}")
        return None

##########################
# Planning Module Code #
##########################

def extract_case_facts(client, case_description):
    """Extract key facts from case description"""
    try:
        prompt = (
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é —Ñ–∞–±—É–ª—É –¥–µ–ª–∞ –∏ –≤—ã–¥–µ–ª–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã, –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤–∞, "
            "–¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –∏ —É—á–∞—Å—Ç–Ω–∏–∫–æ–≤. –ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤ –≤–∏–¥–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ —Å–ø–∏—Å–∫–∞:\n\n" + 
            case_description
        )
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–í—ã –æ–ø—ã—Ç–Ω—ã–π —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤ –¥–µ–ª."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ —Ñ–∞–±—É–ª—ã –¥–µ–ª–∞: {str(e)}")
        return None

def determine_crime_classification(client, facts):
    """Determine crime classification and relevant legal articles"""
    try:
        prompt = (
            "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ —Ñ–∞–∫—Ç—ã –¥–µ–ª–∞ –∏ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç–µ:\n"
            "1. –ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—é –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è (—Ç–∏–ø –∏ –∫–∞—Ç–µ–≥–æ—Ä–∏—é)\n"
            "2. –°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ —Å—Ç–∞—Ç—å–∏ –£–ö –†–ö\n"
            "–ü—Ä–µ–¥—Å—Ç–∞–≤—å—Ç–µ –æ—Ç–≤–µ—Ç –≤ —Ñ–æ—Ä–º–∞—Ç–µ: –ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è: [–∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è], –°—Ç–∞—Ç—å–∏: [—Å–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–µ–π]\n\n" +
            facts
        )
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–í—ã –æ–ø—ã—Ç–Ω—ã–π —é—Ä–∏—Å—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–π –ø–æ –∑–∞–∫–æ–Ω–æ–¥–∞—Ç–µ–ª—å—Å—Ç–≤—É –†–µ—Å–ø—É–±–ª–∏–∫–∏ –ö–∞–∑–∞—Ö—Å—Ç–∞–Ω."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏: {str(e)}")
        return None

def create_investigation_plan(client, facts, classification, methodology_text=None):
    """Create investigation plan based on facts, classification and methodology"""
    try:
        methodology_part = ""
        if methodology_text:
            methodology_part = f"\n–ü—Ä–∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –ø–ª–∞–Ω–∞ –∏—Å–ø–æ–ª—å–∑—É–π—Ç–µ —Å–ª–µ–¥—É—é—â—É—é –º–µ—Ç–æ–¥–∏–∫—É:\n{methodology_text}\n"
            
        prompt = (
            f"–°–æ—Å—Ç–∞–≤—å—Ç–µ –ø–ª–∞–Ω —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–∏—Ö —Ñ–∞–∫—Ç–æ–≤ –∏ –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏–∏ –¥–µ–ª–∞:{methodology_part}\n\n"
            f"–§–ê–ö–¢–´:\n{facts}\n\n"
            f"–ö–í–ê–õ–ò–§–ò–ö–ê–¶–ò–Ø:\n{classification}\n\n"
            "–ü–ª–∞–Ω –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å:\n"
            "1. –í–µ—Ä—Å–∏–∏ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (–Ω–µ –º–µ–Ω–µ–µ 2-3)\n"
            "2. –ü–µ—Ä–≤–æ–æ—á–µ—Ä–µ–¥–Ω—ã–µ —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è\n"
            "3. –ü–æ—Å–ª–µ–¥—É—é—â–∏–µ —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–µ–π—Å—Ç–≤–∏—è\n"
            "4. –ù–µ–æ–±—Ö–æ–¥–∏–º—ã–µ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—ã\n"
            "5. –û–ø–µ—Ä–∞—Ç–∏–≤–Ω–æ-—Ä–æ–∑—ã—Å–∫–Ω—ã–µ –º–µ—Ä–æ–ø—Ä–∏—è—Ç–∏—è\n\n"
            "–î–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–µ–π—Å—Ç–≤–∏—è —É–∫–∞–∂–∏—Ç–µ —Ü–µ–ª—å, –æ–∂–∏–¥–∞–µ–º—ã–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç –∏ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç."
        )
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–í—ã –æ–ø—ã—Ç–Ω—ã–π —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å —Å –º–Ω–æ–≥–æ–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏—è —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–π."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –ø–ª–∞–Ω–∞: {str(e)}")
        return None

def process_methodology(client, uploaded_file):
    """Process methodology file and extract key points"""
    try:
        # Save file temporarily
        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf') as tmpfile:
            tmpfile.write(uploaded_file.getbuffer())
            file_path = tmpfile.name
            
        # Extract text from PDF - this is a simplified version
        # In a real application, you would use a PDF parsing library
        prompt = f"–ò–∑ —ç—Ç–æ–π –º–µ—Ç–æ–¥–∏–∫–∏ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –≤—ã–¥–µ–ª–∏—Ç–µ –∫–ª—é—á–µ–≤—ã–µ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏, –∞–ª–≥–æ—Ä–∏—Ç–º—ã –¥–µ–π—Å—Ç–≤–∏–π –∏ –≤–∞–∂–Ω—ã–µ –º–æ–º–µ–Ω—Ç—ã, –∫–æ—Ç–æ—Ä—ã–µ —Å–ª–µ–¥—É–µ—Ç —É—á–∏—Ç—ã–≤–∞—Ç—å –ø—Ä–∏ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–∏ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è."
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–í—ã —ç–∫—Å–ø–µ—Ä—Ç –ø–æ –º–µ—Ç–æ–¥–∏–∫–∞–º —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏–π."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
        )
        
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –º–µ—Ç–æ–¥–∏–∫–∏: {str(e)}")
        return None
    finally:
        if os.path.exists(file_path):
            os.remove(file_path)

##########################
# Indictment Module Code #
##########################

def generate_indictment(client, case_number, crime_description, suspect_info, evidence_list, additional_info=None):
    """Generate indictment based on case information"""
    try:
        # Create evidence text, handling both regular and file evidence
        evidence_items = []
        for evidence in evidence_list:
            evidence_text = f"- {evidence.get('type')}: {evidence.get('description')}"
            if evidence.get('fileName'):
                evidence_text += f" (–§–∞–π–ª: {evidence.get('fileName')})"
            evidence_items.append(evidence_text)
        
        evidence_text = "\n".join(evidence_items)
        
        additional_part = ""
        if additional_info:
            additional_part = f"\n–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è:\n{additional_info}"
            
        prompt = (
            f"–°–æ—Å—Ç–∞–≤—å—Ç–µ –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–∫—Ç –ø–æ –¥–µ–ª—É ‚Ññ{case_number} –Ω–∞ –æ—Å–Ω–æ–≤–µ —Å–ª–µ–¥—É—é—â–µ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏:\n\n"
            f"–û–ü–ò–°–ê–ù–ò–ï –ü–†–ï–°–¢–£–ü–õ–ï–ù–ò–Ø:\n{crime_description}\n\n"
            f"–î–ê–ù–ù–´–ï –û –ü–û–î–û–ó–†–ï–í–ê–ï–ú–û–ú:\n{suspect_info}\n\n"
            f"–î–û–ö–ê–ó–ê–¢–ï–õ–¨–°–¢–í–ê:\n{evidence_text}{additional_part}\n\n"
            "–û–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–∫—Ç –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å:\n"
            "1. –í–≤–æ–¥–Ω—É—é —á–∞—Å—Ç—å (–¥–∞–Ω–Ω—ã–µ –æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º, –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è –¥–µ—è–Ω–∏—è)\n"
            "2. –û–ø–∏—Å–∞—Ç–µ–ª—å–Ω—É—é —á–∞—Å—Ç—å (–æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è, –µ–≥–æ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤)\n"
            "3. –î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–µ–Ω–Ω—É—é —á–∞—Å—Ç—å (–ø–µ—Ä–µ—á–µ–Ω—å –∏ –∞–Ω–∞–ª–∏–∑ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤)\n"
            "4. –Æ—Ä–∏–¥–∏—á–µ—Å–∫—É—é –∫–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—é (–ø—Ä–∞–≤–æ–≤–∞—è –æ—Ü–µ–Ω–∫–∞ –¥–µ—è–Ω–∏—è)\n"
            "5. –ó–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω—É—é —á–∞—Å—Ç—å (–ø—Ä–æ—Ü–µ—Å—Å—É–∞–ª—å–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è)"
        )
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–í—ã –æ–ø—ã—Ç–Ω—ã–π –ø—Ä–æ–∫—É—Ä–æ—Ä, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∞–∫—Ç–æ–≤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–∫—Ç–∞: {str(e)}")
        return None

def analyze_evidence(client, evidence_list, crime_description):
    """Analyze evidence in relation to crime description"""
    try:
        # Create evidence text, handling both regular and file evidence
        evidence_items = []
        for evidence in evidence_list:
            evidence_text = f"- {evidence.get('type')}: {evidence.get('description')}"
            if evidence.get('fileName'):
                evidence_text += f" (–§–∞–π–ª: {evidence.get('fileName')})"
                # Include file content snippet if available
                if evidence.get('fileContent'):
                    snippet = evidence.get('fileContent')[:200] + "..." if len(evidence.get('fileContent', '')) > 200 else evidence.get('fileContent', '')
                    if snippet:
                        evidence_text += f"\n  –§—Ä–∞–≥–º–µ–Ω—Ç —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ: {snippet}"
            evidence_items.append(evidence_text)
        
        evidence_text = "\n".join(evidence_items)
        
        prompt = (
            f"–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π—Ç–µ —Å–ª–µ–¥—É—é—â–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ –¥–∞–Ω–Ω–æ–≥–æ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è –∏ –æ—Ü–µ–Ω–∏—Ç–µ –∏—Ö –∑–Ω–∞—á–∏–º–æ—Å—Ç—å, "
            f"–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ—Å—Ç—å –∏ –≤–µ—Ä–æ—è—Ç–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è:\n\n"
            f"–ü–†–ï–°–¢–£–ü–õ–ï–ù–ò–ï:\n{crime_description}\n\n"
            f"–î–û–ö–ê–ó–ê–¢–ï–õ–¨–°–¢–í–ê:\n{evidence_text}\n\n"
            "–ê–Ω–∞–ª–∏–∑ –¥–æ–ª–∂–µ–Ω –≤–∫–ª—é—á–∞—Ç—å:\n"
            "1. –û—Ü–µ–Ω–∫—É –∫–∞–∂–¥–æ–≥–æ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ (–≤–∫–ª—é—á–∞—è —Ñ–∞–π–ª—ã)\n"
            "2. –í—ã—è–≤–ª–µ–Ω–∏–µ –ø—Ä–æ–±–µ–ª–æ–≤ –≤ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–µ–Ω–Ω–æ–π –±–∞–∑–µ\n"
            "3. –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–º –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞–º"
        )
        
        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "–í—ã –æ–ø—ã—Ç–Ω—ã–π —é—Ä–∏—Å—Ç, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏–π—Å—è –Ω–∞ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤ –≤ —É–≥–æ–ª–æ–≤–Ω—ã—Ö –¥–µ–ª–∞—Ö."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.5,
        )
        return response.choices[0].message.content.strip()
    except Exception as e:
        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –∞–Ω–∞–ª–∏–∑–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤: {str(e)}")
        return None

#####################
# Main Application #
#####################

def main():
    # Initialize
    load_css()
    create_directories()
    client = init_openai()
    
    # Check dependencies
    ffmpeg_available = check_ffmpeg()
    
    # Sidebar navigation
    with st.sidebar:
        st.title("üîç –°–∏—Å—Ç–µ–º–∞ –ø–æ–º–æ—â–Ω–∏–∫–∞ —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è")
        
        module = st.radio(
            "–í—ã–±–µ—Ä–∏—Ç–µ –º–æ–¥—É–ª—å:",
            ["–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –ø–æ–∫–∞–∑–∞–Ω–∏–π", "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è", "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∞–∫—Ç–æ–≤"]
        )
        
        if not ffmpeg_available and module == "–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –ø–æ–∫–∞–∑–∞–Ω–∏–π":
            st.error("FFmpeg –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω. –î–ª—è —Ä–∞–±–æ—Ç—ã —Å –≤–∏–¥–µ–æ –∏ –∞—É–¥–∏–æ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ —É—Å—Ç–∞–Ω–æ–≤–∏—Ç—å FFmpeg.")
        
        if not client:
            st.error("OpenAI API –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω. –ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –ø—Ä–æ–≤–µ—Ä—å—Ç–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏ API –∫–ª—é—á–∞.")
    
    # Main content
    if module == "–¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è –ø–æ–∫–∞–∑–∞–Ω–∏–π":
        show_transcription_module(client)
    elif module == "–ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è":
        show_planning_module(client)
    elif module == "–ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∞–∫—Ç–æ–≤":
        show_indictment_module(client)
    
    # Footer
    st.markdown("""
        <div class="footer">
            ¬© 2025 –°–∏—Å—Ç–µ–º–∞ –ø–æ–º–æ—â–Ω–∏–∫–∞ —Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—è | –í–µ—Ä—Å–∏—è 1.0.0
        </div>
    """, unsafe_allow_html=True)

##########################################
# Module Interface Functions
##########################################

def show_transcription_module(client):
    st.title("üéôÔ∏è –¢—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è —Å–ª–µ–¥—Å—Ç–≤–µ–Ω–Ω—ã—Ö –¥–µ–π—Å—Ç–≤–∏–π")
    
    # Create tabs for main functionality and history
    tab1, tab2 = st.tabs(["–ù–æ–≤–∞—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏—è", "–ò—Å—Ç–æ—Ä–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–π"])
    
    with tab1:
        st.header("–ó–∞–≥—Ä—É–∑–∫–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞ –∞—É–¥–∏–æ/–≤–∏–¥–µ–æ")
        
        # Form for transcription
        with st.form("transcription_form"):
            case_number = st.text_input("–ù–æ–º–µ—Ä –º–∞—Ç–µ—Ä–∏–∞–ª–∞", value=generate_case_number(), disabled=True)
            
            language = st.selectbox(
                "–Ø–∑—ã–∫ –º–∞—Ç–µ—Ä–∏–∞–ª–∞",
                options=[("ru", "üá∑üá∫ –†—É—Å—Å–∫–∏–π"), ("kk", "üá∞üáø “ö–∞–∑–∞“õ —Ç—ñ–ª—ñ"), ("en", "üá¨üáß English")],
                format_func=lambda x: x[1]
            )
            
            st.subheader("–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤")
            uploaded_file1 = st.file_uploader(
                "–ü–æ–∫–∞–∑–∞–Ω–∏—è –ª–∏—Ü–∞ ‚Ññ1", 
                type=["mp4", "avi", "mov", "mp3", "wav"],
                key="file1"
            )
            
            uploaded_file2 = st.file_uploader(
                "–ü–æ–∫–∞–∑–∞–Ω–∏—è –ª–∏—Ü–∞ ‚Ññ2 (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)", 
                type=["mp4", "avi", "mov", "mp3", "wav"],
                key="file2"
            )
            
            st.subheader("–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—ã–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã")
            description = st.text_area("–û–ø–∏—Å–∞–Ω–∏–µ –º–∞—Ç–µ—Ä–∏–∞–ª–∞ (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ)")
            
            col1, col2 = st.columns(2)
            with col1:
                analyze_sequence = st.checkbox("–ê–Ω–∞–ª–∏–∑–∏—Ä–æ–≤–∞—Ç—å –ª–æ–≥–∏—á–µ—Å–∫—É—é –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å", value=True)
                extract_facts = st.checkbox("–ò–∑–≤–ª–µ–∫–∞—Ç—å –∫–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã", value=True)
            
            with col2:
                find_contradictions = st.checkbox("–ò—Å–∫–∞—Ç—å –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è", value=True)
                generate_questions_check = st.checkbox("–ì–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å —É—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã", value=True)
            
            submit_button = st.form_submit_button("–ù–∞—á–∞—Ç—å –æ–±—Ä–∞–±–æ—Ç–∫—É")
        
        if submit_button:
            if not uploaded_file1:
                st.error("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–≥—Ä—É–∑–∏—Ç—å —Ñ–∞–π–ª —Å –ø–æ–∫–∞–∑–∞–Ω–∏—è–º–∏ –ª–∏—Ü–∞ ‚Ññ1")
                return
            
            with st.spinner("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–æ–≤..."):
                try:
                    transcription_results = {"id": case_number, "language": language[0], "generatedDate": datetime.datetime.now().isoformat()}
                    transcription_results["description"] = description
                    transcription_results["statements"] = []
                    
                    # Process first file
                    st.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –ª–∏—Ü–∞ ‚Ññ1...")
                    audio_path1 = extract_audio(uploaded_file1)
                    transcription1 = transcribe_audio(client, audio_path1, language[0])
                    
                    statement1 = {
                        "witnessName": "–õ–∏—Ü–æ ‚Ññ1",
                        "fileUrl": uploaded_file1.name,
                        "transcription": transcription1,
                        "summary": "",
                        "logicalAnalysis": "",
                        "keyFacts": []
                    }
                    
                    # Analyze first transcription
                    if transcription1:
                        if analyze_sequence:
                            statement1["logicalAnalysis"] = analyze_transcription(client, transcription1, "sequence", language[0])
                        
                        if extract_facts:
                            facts_text = analyze_transcription(client, transcription1, "facts", language[0])
                            statement1["keyFacts"] = [fact.strip() for fact in facts_text.split('\n') if fact.strip()]
                        
                        statement1["summary"] = analyze_transcription(client, transcription1, "summary", language[0])
                    
                    transcription_results["statements"].append(statement1)
                    
                    # Process second file if uploaded
                    transcription2 = None
                    if uploaded_file2:
                        st.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ —Ñ–∞–π–ª–∞ –ª–∏—Ü–∞ ‚Ññ2...")
                        audio_path2 = extract_audio(uploaded_file2)
                        transcription2 = transcribe_audio(client, audio_path2, language[0])
                        
                        statement2 = {
                            "witnessName": "–õ–∏—Ü–æ ‚Ññ2",
                            "fileUrl": uploaded_file2.name,
                            "transcription": transcription2,
                            "summary": "",
                            "logicalAnalysis": "",
                            "keyFacts": []
                        }
                        
                        # Analyze second transcription
                        if transcription2:
                            if analyze_sequence:
                                statement2["logicalAnalysis"] = analyze_transcription(client, transcription2, "sequence", language[0])
                            
                            if extract_facts:
                                facts_text = analyze_transcription(client, transcription2, "facts", language[0])
                                statement2["keyFacts"] = [fact.strip() for fact in facts_text.split('\n') if fact.strip()]
                            
                            statement2["summary"] = analyze_transcription(client, transcription2, "summary", language[0])
                        
                        transcription_results["statements"].append(statement2)
                    
                    # Compare testimonies if requested
                    transcription_results['contradictions'] = [] 
                    if find_contradictions and transcription1 and transcription2: 
                        st.info("–°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø–æ–∫–∞–∑–∞–Ω–∏–π –∏ –ø–æ–∏—Å–∫ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π...")
                        contradictions_result = compare_testimonies(client, transcription1, transcription2)
                        if contradictions_result is not None:
                            transcription_results['contradictions'] = contradictions_result # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–ø–∏—Å–æ–∫
                            if not contradictions_result: st.info("–°—É—â–µ—Å—Ç–≤–µ–Ω–Ω—ã—Ö –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏–π –Ω–µ –≤—ã—è–≤–ª–µ–Ω–æ.")
                        else: st.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å—Ä–∞–≤–Ω–∏—Ç—å –ø–æ–∫–∞–∑–∞–Ω–∏—è –∏–∑-–∑–∞ –æ—à–∏–±–∫–∏ API.")

                    # Generate questions if requested and contradictions found
                    transcription_results['suggestedQuestions'] = [] 
                    if generate_questions_check and transcription_results['contradictions']:
                        st.info("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è —É—Ç–æ—á–Ω—è—é—â–∏—Ö –≤–æ–ø—Ä–æ—Å–æ–≤...")
                        contradictions_text = "\n".join([f"- {c.get('description', '')}" for c in transcription_results['contradictions']])
                        questions = generate_questions(client, contradictions_text)
                        if questions:
                             question_items = [q.strip() for q in questions.split('\n') if q.strip()]
                             transcription_results["suggestedQuestions"] = question_items
                        else: st.error("–ù–µ —É–¥–∞–ª–æ—Å—å —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞—Ç—å –≤–æ–ø—Ä–æ—Å—ã.")
                    
                    # Save results
                    save_history("transcriptions", transcription_results)
                    
                    # Display success message
                    st.success("–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞ —É—Å–ø–µ—à–Ω–æ!")
                    
                    # Create DOCX document
                    content_sections = []
                    
                    # Add statements
                    for i, statement in enumerate(transcription_results.get('statements', []), 1):
                        content_sections.append({
                            'heading': f"–ü–æ–∫–∞–∑–∞–Ω–∏—è –ª–∏—Ü–∞ #{i}",
                            'content': statement.get('transcription', '')
                        })
                        
                        if statement.get('summary'):
                            content_sections.append({
                                'heading': f"–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –ø–æ–∫–∞–∑–∞–Ω–∏–π –ª–∏—Ü–∞ #{i}",
                                'content': statement.get('summary', '')
                            })
                            
                        if statement.get('keyFacts'):
                            content_sections.append({
                                'heading': f"–ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –ø–æ–∫–∞–∑–∞–Ω–∏–π –ª–∏—Ü–∞ #{i}",
                                'content': statement.get('keyFacts', [])
                            })
                    
                    # Add contradictions if any
                    if transcription_results.get('contradictions'):
                        contradictions_content = []
                        for contradiction in transcription_results.get('contradictions', []):
                            contradictions_content.append(contradiction.get('description', ''))
                        
                        content_sections.append({
                            'heading': "–í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è",
                            'content': contradictions_content
                        })
                    
                    # Add questions if any
                    if transcription_results.get('suggestedQuestions'):
                        content_sections.append({
                            'heading': "–£—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã",
                            'content': transcription_results.get('suggestedQuestions', [])
                        })
                    
                    # Create metadata
                    metadata = {
                        "–ù–æ–º–µ—Ä –º–∞—Ç–µ—Ä–∏–∞–ª–∞": transcription_results.get('id', ''),
                        "–î–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏": transcription_results.get('generatedDate', '')[:10],
                        "–Ø–∑—ã–∫": transcription_results.get('language', '')
                    }
                    
                    docx_bytes = create_docx_document(
                        f"–ü—Ä–æ—Ç–æ–∫–æ–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ {transcription_results.get('id', '')}",
                        content_sections,
                        metadata
                    )
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.download_button(
                            "üìÑ –°–∫–∞—á–∞—Ç—å –ø—Ä–æ—Ç–æ–∫–æ–ª (DOCX)",
                            data=docx_bytes,
                            file_name=f"transcription_{transcription_results['id']}.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            key=f"download_docx_main_{transcription_results['id']}"
                        )
                    
                    with col2:
                        st.download_button(
                            "üìä –°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (JSON)",
                            data=json.dumps(transcription_results, ensure_ascii=False, indent=2),
                            file_name=f"transcription_{transcription_results['id']}.json",
                            mime="application/json",
                            key=f"download_json_main_{transcription_results['id']}"
                        )
                    
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {str(e)}")
    
    with tab2:
        st.header("–ò—Å—Ç–æ—Ä–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–π")
        
        # Load history
        history = load_history("transcriptions")
        
        if not history:
            st.info("–ò—Å—Ç–æ—Ä–∏—è —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–π –ø—É—Å—Ç–∞")
        else:
            for item in history:
                with st.expander(f"–ú–∞—Ç–µ—Ä–∏–∞–ª {item['id']} –æ—Ç {item.get('generatedDate', 'N/A')[:10]}"):
                    st.write(f"**–Ø–∑—ã–∫:** {item.get('language', '–ù–µ —É–∫–∞–∑–∞–Ω')}")
                    st.write(f"**–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤:** {len(item.get('statements', []))}")
                    
                    # –ó–∞–º–µ–Ω—è–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ expander –Ω–∞ tabs
                    tab_titles = [f"–ü–æ–∫–∞–∑–∞–Ω–∏—è {s.get('witnessName', f'–õ–∏—Ü–æ #{i+1}')}" for i, s in enumerate(item.get('statements', []))]
                    if tab_titles:
                        tabs = st.tabs(tab_titles)
                        for i, statement in enumerate(item.get('statements', [])):
                             with tabs[i]:
                                st.write(f"–§–∞–π–ª: {statement.get('fileUrl', '–ù–µ —É–∫–∞–∑–∞–Ω')}")
                                st.text_area("–¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è", statement.get('transcription', ''), height=200, key=f"hist_transcription_{item['id']}_{i}", label_visibility="collapsed")
                                
                                # –£–±–∏—Ä–∞–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ expander –¥–ª—è –¥–µ—Ç–∞–ª–µ–π
                                if statement.get('summary'):
                                    st.subheader("–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ")
                                    st.write(statement.get('summary', ''))
                                if statement.get('logicalAnalysis'):
                                    st.subheader("–ê–Ω–∞–ª–∏–∑ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç–∏")
                                    st.write(statement.get('logicalAnalysis', ''))
                                if statement.get('keyFacts'):
                                    st.subheader("–ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã")
                                    if isinstance(statement.get('keyFacts'), list):
                                        for fact in statement.get('keyFacts', []):
                                            st.markdown(f"- {fact}")
                                    else: st.write(statement.get('keyFacts', ''))
                    
                    # Show contradictions if any
                    if 'contradictions' in item and item['contradictions']:
                        st.subheader("–í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è")
                        if isinstance(item['contradictions'], list):
                            for contradiction in item['contradictions']:
                                if isinstance(contradiction, dict):
                                    st.markdown(f"**- {contradiction.get('description', '–ù–µ—Ç –æ–ø–∏—Å–∞–Ω–∏—è')}** (–ó–Ω–∞—á–∏–º–æ—Å—Ç—å: {contradiction.get('significance', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')})")
                                    st.caption(f"  _–õ–∏—Ü–æ 1:_ {contradiction.get('quote1', '–¶–∏—Ç–∞—Ç–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}")
                                    st.caption(f"  _–õ–∏—Ü–æ 2:_ {contradiction.get('quote2', '–¶–∏—Ç–∞—Ç–∞ –æ—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç')}")
                                elif isinstance(contradiction, str): st.markdown(f"- {contradiction}") 
                        elif isinstance(item['contradictions'], str): st.markdown(item['contradictions'])
                    
                    # Show questions if any
                    if item.get('suggestedQuestions'):
                        st.subheader("–£—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã")
                        for i, question in enumerate(item.get('suggestedQuestions', []), 1):
                            st.markdown(f"{i}. {question}")
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.download_button(
                            "–°–∫–∞—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã (JSON)",
                            data=json.dumps(item, ensure_ascii=False, indent=2),
                            file_name=f"transcription_{item['id']}.json",
                            mime="application/json",
                            key=f"download_json_hist_{item['id']}"
                        )
                    
                    with col2:
                        # Create DOCX document for download
                        content_sections = []
                        
                        # Add statements
                        for i, statement in enumerate(item.get('statements', []), 1):
                            content_sections.append({
                                'heading': f"–ü–æ–∫–∞–∑–∞–Ω–∏—è –ª–∏—Ü–∞ #{i}",
                                'content': statement.get('transcription', '')
                            })
                            
                            if statement.get('summary'):
                                content_sections.append({
                                    'heading': f"–ö—Ä–∞—Ç–∫–æ–µ —Ä–µ–∑—é–º–µ –ø–æ–∫–∞–∑–∞–Ω–∏–π –ª–∏—Ü–∞ #{i}",
                                    'content': statement.get('summary', '')
                                })
                                
                            if statement.get('keyFacts'):
                                content_sections.append({
                                    'heading': f"–ö–ª—é—á–µ–≤—ã–µ —Ñ–∞–∫—Ç—ã –ø–æ–∫–∞–∑–∞–Ω–∏–π –ª–∏—Ü–∞ #{i}",
                                    'content': statement.get('keyFacts', [])
                                })
                        
                        # Add contradictions if any
                        if item.get('contradictions'):
                            contradictions_content = []
                            for contradiction in item.get('contradictions', []):
                                contradictions_content.append(contradiction.get('description', ''))
                            
                            content_sections.append({
                                'heading': "–í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ—Ç–∏–≤–æ—Ä–µ—á–∏—è",
                                'content': contradictions_content
                            })
                        
                        # Add questions if any
                        if item.get('suggestedQuestions'):
                            content_sections.append({
                                'heading': "–£—Ç–æ—á–Ω—è—é—â–∏–µ –≤–æ–ø—Ä–æ—Å—ã",
                                'content': item.get('suggestedQuestions', [])
                            })
                        
                        # Create metadata
                        metadata = {
                            "–ù–æ–º–µ—Ä –º–∞—Ç–µ—Ä–∏–∞–ª–∞": item.get('id', ''),
                            "–î–∞—Ç–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏": item.get('generatedDate', '')[:10],
                            "–Ø–∑—ã–∫": item.get('language', '')
                        }
                        
                        docx_bytes = create_docx_document(
                            f"–ü—Ä–æ—Ç–æ–∫–æ–ª —Ç—Ä–∞–Ω—Å–∫—Ä–∏–±–∞—Ü–∏–∏ {item.get('id', '')}",
                            content_sections,
                            metadata
                        )
                        
                        st.download_button(
                            "–°–∫–∞—á–∞—Ç—å (DOCX)",
                            data=docx_bytes,
                            file_name=f"transcription_{item['id']}.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            key=f"download_docx_hist_{item['id']}"
                        )
                    
                    with col3:
                        if st.button("–£–¥–∞–ª–∏—Ç—å", key=f"delete_transcription_{item['id']}"):
                            # Implement deletion logic here
                            st.warning("–§—É–Ω–∫—Ü–∏—è —É–¥–∞–ª–µ–Ω–∏—è –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ —Å–ª–µ–¥—É—é—â–µ–π –≤–µ—Ä—Å–∏–∏")

def show_planning_module(client):
    st.title("üìã –ü–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
    
    # Create tabs for main functionality and history
    tab1, tab2 = st.tabs(["–ù–æ–≤—ã–π –ø–ª–∞–Ω", "–ò—Å—Ç–æ—Ä–∏—è –ø–ª–∞–Ω–æ–≤"])
    
    with tab1:
        st.header("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
        
        # Form for investigation planning
        with st.form("planning_form"):
            case_number = st.text_input("–ù–æ–º–µ—Ä –¥–µ–ª–∞", help="–í–≤–µ–¥–∏—Ç–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –¥–µ–ª–∞")
            
            case_description = st.text_area(
                "–û–ø–∏—Å–∞–Ω–∏–µ —Ñ–∞–±—É–ª—ã –¥–µ–ª–∞", 
                height=200,
                help="–í–≤–µ–¥–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ –æ–±—Å—Ç–æ—è—Ç–µ–ª—å—Å—Ç–≤ –¥–µ–ª–∞"
            )
            
            crime_category = st.selectbox(
                "–ö–∞—Ç–µ–≥–æ—Ä–∏—è –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è",
                options=[
                    ("", "-- –í—ã–±–µ—Ä–∏—Ç–µ –∫–∞—Ç–µ–≥–æ—Ä–∏—é (–Ω–µ–æ–±—è–∑–∞—Ç–µ–ª—å–Ω–æ) --"),
                    ("theft", "–ö—Ä–∞–∂–∞"),
                    ("robbery", "–ì—Ä–∞–±–µ–∂"),
                    ("fraud", "–ú–æ—à–µ–Ω–Ω–∏—á–µ—Å—Ç–≤–æ"),
                    ("murder", "–£–±–∏–π—Å—Ç–≤–æ"),
                    ("assault", "–ù–∞–Ω–µ—Å–µ–Ω–∏–µ —Ç–µ–ª–µ—Å–Ω—ã—Ö –ø–æ–≤—Ä–µ–∂–¥–µ–Ω–∏–π"),
                    ("drugTrafficking", "–ù–µ–∑–∞–∫–æ–Ω–Ω—ã–π –æ–±–æ—Ä–æ—Ç –Ω–∞—Ä–∫–æ—Ç–∏–∫–æ–≤"),
                    ("other", "–î—Ä—É–≥–æ–µ")
                ],
                format_func=lambda x: x[1]
            )
            
            suspect_info = st.text_area(
                "–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º (–µ—Å–ª–∏ –∏–∑–≤–µ—Å—Ç–Ω–∞)",
                height=100
            )
            
            methodology_file = st.file_uploader(
                "–ó–∞–≥—Ä—É–∑–∏—Ç—å –º–µ—Ç–æ–¥–∏–∫—É —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è (PDF)",
                type=["pdf"],
                help="–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª –º–µ—Ç–æ–¥–∏–∫–∏ –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π"
            )
            
            use_methodology = st.checkbox("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –±–∞–∑—É –º–µ—Ç–æ–¥–∏–∫ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è", value=True)
            
            submit_button = st.form_submit_button("–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –ø–ª–∞–Ω —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
        
        if submit_button:
            if not case_number or not case_description:
                st.error("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –Ω–æ–º–µ—Ä –¥–µ–ª–∞ –∏ –æ–ø–∏—Å–∞–Ω–∏–µ —Ñ–∞–±—É–ª—ã")
                return
            
            with st.spinner("–ê–Ω–∞–ª–∏–∑ –¥–µ–ª–∞ –∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–ª–∞–Ω–∞..."):
                try:
                    # Extract facts from case description
                    facts = extract_case_facts(client, case_description)
                    
                    # Determine crime classification
                    classification = determine_crime_classification(client, facts)
                    
                    # Process methodology if provided
                    methodology_text = None
                    if methodology_file and use_methodology:
                        st.info("–û–±—Ä–∞–±–æ—Ç–∫–∞ –º–µ—Ç–æ–¥–∏–∫–∏ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è...")
                        methodology_text = process_methodology(client, methodology_file)
                    
                    # Create investigation plan
                    st.info("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–ª–∞–Ω–∞ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è...")
                    plan = create_investigation_plan(client, facts, classification, methodology_text)
                    
                    # Prepare results
                    planning_results = {
                        "id": case_number,
                        "caseNumber": case_number,
                        "crimeCategory": crime_category[0] if crime_category[0] else "–ù–µ —É–∫–∞–∑–∞–Ω–∞",
                        "suspectInfo": suspect_info,
                        "caseDescription": case_description,
                        "extractedFacts": facts,
                        "crimeClassification": classification,
                        "generatedDate": datetime.datetime.now().isoformat(),
                        "plan": plan
                    }
                    
                    # Parse classification to extract legal articles
                    try:
                        legal_articles = []
                        if "–°—Ç–∞—Ç—å–∏:" in classification:
                            articles_part = classification.split("–°—Ç–∞—Ç—å–∏:")[1].strip()
                            legal_articles = [art.strip() for art in articles_part.split(",")]
                        planning_results["legalArticles"] = legal_articles
                    except:
                        planning_results["legalArticles"] = []
                    
                    # Add methodology information
                    if methodology_text:
                        planning_results["methodologyUsed"] = True
                        planning_results["methodologyReferences"] = ["–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –º–µ—Ç–æ–¥–∏–∫–∞"]
                    else:
                        planning_results["methodologyUsed"] = use_methodology
                        planning_results["methodologyReferences"] = []
                    
                    # Save results
                    save_history("planning", planning_results)
                    
                    # Display results
                    st.success("–ü–ª–∞–Ω —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è —É—Å–ø–µ—à–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω!")
                    
                    st.subheader("–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã")
                    st.markdown(facts)
                    
                    st.subheader("–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è")
                    st.markdown(classification)
                    
                    st.subheader("–ü–ª–∞–Ω —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
                    st.markdown(plan)
                    
                    # Create DOCX document
                    content_sections = []
                    
                    # Add case description
                    content_sections.append({
                        'heading': "–§–∞–±—É–ª–∞ –¥–µ–ª–∞",
                        'content': case_description
                    })
                    
                    # Add extracted facts
                    content_sections.append({
                        'heading': "–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã",
                        'content': facts
                    })
                    
                    # Add crime classification
                    content_sections.append({
                        'heading': "–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è",
                        'content': classification
                    })
                    
                    # Add investigation plan
                    content_sections.append({
                        'heading': "–ü–ª–∞–Ω —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
                        'content': plan
                    })
                    
                    # Add methodology information if any
                    if methodology_text:
                        content_sections.append({
                            'heading': "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω–∞—è –º–µ—Ç–æ–¥–∏–∫–∞",
                            'content': "–ó–∞–≥—Ä—É–∂–µ–Ω–Ω–∞—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º –º–µ—Ç–æ–¥–∏–∫–∞"
                        })
                    
                    # Create metadata
                    metadata = {
                        "–ù–æ–º–µ—Ä –¥–µ–ª–∞": case_number,
                        "–î–∞—Ç–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è": datetime.datetime.now().strftime("%Y-%m-%d"),
                        "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": planning_results.get('crimeCategory', '–ù–µ —É–∫–∞–∑–∞–Ω–∞')
                    }
                    
                    docx_bytes = create_docx_document(
                        f"–ü–ª–∞–Ω —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ –¥–µ–ª—É {case_number}",
                        content_sections,
                        metadata
                    )
                    
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.download_button(
                            "üìÑ –°–∫–∞—á–∞—Ç—å –ø–ª–∞–Ω (DOCX)",
                            data=docx_bytes,
                            file_name=f"plan_{case_number}.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            key=f"download_plan_docx_main_{case_number}"
                        )
                    
                    with col2:
                        st.download_button(
                            "üìä –°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (JSON)",
                            data=json.dumps(planning_results, ensure_ascii=False, indent=2),
                            file_name=f"plan_{case_number}.json",
                            mime="application/json",
                            key=f"download_plan_json_main_{case_number}"
                        )
                    
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –ø–ª–∞–Ω–∞: {str(e)}")
    
    with tab2:
        st.header("–ò—Å—Ç–æ—Ä–∏—è –ø–ª–∞–Ω–æ–≤ —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è")
        
        # Load history
        history = load_history("planning")
        
        if not history:
            st.info("–ò—Å—Ç–æ—Ä–∏—è –ø–ª–∞–Ω–æ–≤ –ø—É—Å—Ç–∞")
        else:
            for item in history:
                with st.expander(f"–î–µ–ª–æ {item.get('caseNumber', 'N/A')} –æ—Ç {item.get('generatedDate', 'N/A')[:10]}"):
                    # –ó–∞–º–µ–Ω—è–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ expander –Ω–∞ tabs
                    tab1, tab2, tab3, tab4 = st.tabs(["–û–ø–∏—Å–∞–Ω–∏–µ –¥–µ–ª–∞", "–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã", "–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è", "–ü–ª–∞–Ω —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è"])
                    with tab1: st.write(item.get('caseDescription', ''))
                    with tab2: st.write(item.get('extractedFacts', ''))
                    with tab3: st.write(item.get('crimeClassification', ''))
                    with tab4: st.write(item.get('plan', ''))
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.download_button(
                            "–°–∫–∞—á–∞—Ç—å –ø–ª–∞–Ω (JSON)",
                            data=json.dumps(item, ensure_ascii=False, indent=2),
                            file_name=f"plan_{item.get('caseNumber', 'case')}.json",
                            mime="application/json",
                            key=f"download_plan_json_hist_{item.get('id', '')}"
                        )
                    
                    with col2:
                        # Create DOCX document for download
                        content_sections = []
                        
                        # Add case description
                        content_sections.append({
                            'heading': "–§–∞–±—É–ª–∞ –¥–µ–ª–∞",
                            'content': item.get('caseDescription', '')
                        })
                        
                        # Add extracted facts
                        content_sections.append({
                            'heading': "–ò–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ñ–∞–∫—Ç—ã",
                            'content': item.get('extractedFacts', '')
                        })
                        
                        # Add crime classification
                        content_sections.append({
                            'heading': "–ö–≤–∞–ª–∏—Ñ–∏–∫–∞—Ü–∏—è –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è",
                            'content': item.get('crimeClassification', '')
                        })
                        
                        # Add investigation plan
                        content_sections.append({
                            'heading': "–ü–ª–∞–Ω —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è",
                            'content': item.get('plan', '')
                        })
                        
                        # Add methodology references if any
                        if item.get('methodologyReferences'):
                            content_sections.append({
                                'heading': "–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–Ω—ã–µ –º–µ—Ç–æ–¥–∏–∫–∏",
                                'content': item.get('methodologyReferences', [])
                            })
                        
                        # Create metadata
                        metadata = {
                            "–ù–æ–º–µ—Ä –¥–µ–ª–∞": item.get('caseNumber', ''),
                            "–î–∞—Ç–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è": item.get('generatedDate', '')[:10],
                            "–ö–∞—Ç–µ–≥–æ—Ä–∏—è": item.get('crimeCategory', '')
                        }
                        
                        docx_bytes = create_docx_document(
                            f"–ü–ª–∞–Ω —Ä–∞—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏—è –ø–æ –¥–µ–ª—É {item.get('caseNumber', '')}",
                            content_sections,
                            metadata
                        )
                        
                        st.download_button(
                            "–°–∫–∞—á–∞—Ç—å (DOCX)",
                            data=docx_bytes,
                            file_name=f"plan_{item.get('caseNumber', '')}.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            key=f"download_plan_docx_hist_{item.get('id', '')}"
                        )
                    
                    with col3:
                        if st.button("–£–¥–∞–ª–∏—Ç—å", key=f"delete_planning_{item.get('id', '')}"):
                            # Implement deletion logic here
                            st.warning("–§—É–Ω–∫—Ü–∏—è —É–¥–∞–ª–µ–Ω–∏—è –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ —Å–ª–µ–¥—É—é—â–µ–π –≤–µ—Ä—Å–∏–∏")

def show_indictment_module(client):
    st.title("üßë‚Äç‚öñÔ∏è –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∞–∫—Ç–æ–≤")
    
    # Create tabs for main functionality and history
    tab1, tab2 = st.tabs(["–ù–æ–≤—ã–π –∞–∫—Ç", "–ò—Å—Ç–æ—Ä–∏—è –∞–∫—Ç–æ–≤"])
    
    with tab1:
        st.header("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–∫—Ç–∞")
        
        # Form for indictment generation
        with st.form("indictment_form"):
            case_number = st.text_input("–ù–æ–º–µ—Ä –¥–µ–ª–∞", help="–í–≤–µ–¥–∏—Ç–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–π –Ω–æ–º–µ—Ä –¥–µ–ª–∞")
            
            crime_description = st.text_area(
                "–û–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è", 
                height=200,
                help="–í–≤–µ–¥–∏—Ç–µ –ø–æ–¥—Ä–æ–±–Ω–æ–µ –æ–ø–∏—Å–∞–Ω–∏–µ —Å–æ–±—ã—Ç–∏—è –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è –≤—Ä–µ–º—è, –º–µ—Å—Ç–æ, —Å–ø–æ—Å–æ–± —Å–æ–≤–µ—Ä—à–µ–Ω–∏—è –∏ –ø–æ—Å–ª–µ–¥—Å—Ç–≤–∏—è"
            )
            
            suspect_info = st.text_area(
                "–î–∞–Ω–Ω—ã–µ –æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º",
                height=150,
                help="–£–∫–∞–∂–∏—Ç–µ –§–ò–û, –¥–∞—Ç—É —Ä–æ–∂–¥–µ–Ω–∏—è, –º–µ—Å—Ç–æ –∂–∏—Ç–µ–ª—å—Å—Ç–≤–∞, –≥—Ä–∞–∂–¥–∞–Ω—Å—Ç–≤–æ, –æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏–µ, —Å–µ–º–µ–π–Ω–æ–µ –ø–æ–ª–æ–∂–µ–Ω–∏–µ, –º–µ—Å—Ç–æ —Ä–∞–±–æ—Ç—ã, —Å—É–¥–∏–º–æ—Å—Ç—å"
            )
            
            st.subheader("–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞")
            st.info("–î–æ–±–∞–≤—å—Ç–µ –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞—Ö –ø–æ –¥–µ–ª—É")
            
            # File uploader for evidence files
            uploaded_evidence_files = st.file_uploader(
                "–ó–∞–≥—Ä—É–∑–∏—Ç–µ —Ñ–∞–π–ª—ã –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤", 
                type=["txt", "pdf", "docx", "doc"],
                accept_multiple_files=True,
                help="–ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ–º—ã–µ —Ñ–æ—Ä–º–∞—Ç—ã: TXT, PDF, DOCX, DOC"
            )
            
            # Process uploaded files if any
            evidence_from_files = []
            if uploaded_evidence_files:
                st.subheader("–ó–∞–≥—Ä—É–∂–µ–Ω–Ω—ã–µ —Ñ–∞–π–ª—ã –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤")
                for file in uploaded_evidence_files:
                    # Create a unique file reference ID
                    file_ref = f"{datetime.datetime.now().strftime('%Y%m%d%H%M%S')}_{file.name}"
                    
                    # Store file content
                    file_content = ""
                    try:
                        if file.type == "text/plain":
                            # For txt files
                            file_content = file.getvalue().decode("utf-8")
                        elif file.type == "application/pdf":
                            # For PDF files - in a real app, you'd use a PDF parser here
                            file_content = f"[PDF —Ñ–∞–π–ª: {file.name}]"
                        else:
                            # For other document types
                            file_content = f"[–î–æ–∫—É–º–µ–Ω—Ç: {file.name}]"
                        
                        # Save file to storage
                        create_directories()
                        file_path = f"storage/evidence/{file_ref}"
                        with open(file_path, "wb") as f:
                            f.write(file.getbuffer())
                        
                        # Create evidence item from file
                        col1, col2 = st.columns([1, 3])
                        with col1:
                            file_evidence_type = st.selectbox(
                                f"–¢–∏–ø –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ ({file.name})",
                                options=[
                                    "–ü–æ–∫–∞–∑–∞–Ω–∏—è —Å–≤–∏–¥–µ—Ç–µ–ª—è", "–ü–æ–∫–∞–∑–∞–Ω–∏—è –ø–æ—Ç–µ—Ä–ø–µ–≤—à–µ–≥–æ", "–ü–æ–∫–∞–∑–∞–Ω–∏—è –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ",
                                    "–ó–∞–∫–ª—é—á–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–∞", "–ü—Ä–æ—Ç–æ–∫–æ–ª –æ—Å–º–æ—Ç—Ä–∞", "–ü—Ä–æ—Ç–æ–∫–æ–ª –æ–±—ã—Å–∫–∞", "–ò–Ω–æ–µ"
                                ],
                                key=f"file_evidence_type_{file.name}"
                            )
                        
                        with col2:
                            # If it's a text file, show preview
                            if file.type == "text/plain":
                                with st.expander(f"–ü—Ä–æ—Å–º–æ—Ç—Ä —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞ {file.name}"):
                                    st.text(file_content[:2000] + ("..." if len(file_content) > 2000 else ""))
                            
                            # Allow user to add a description
                            file_evidence_description = st.text_area(
                                f"–û–ø–∏—Å–∞–Ω–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞ ({file.name})",
                                height=100,
                                key=f"file_evidence_description_{file.name}"
                            )
                        
                        # Add to evidence list
                        evidence_from_files.append({
                            "type": file_evidence_type,
                            "description": file_evidence_description if file_evidence_description else f"–§–∞–π–ª: {file.name}",
                            "fileReference": file_ref,
                            "fileName": file.name,
                            "fileContent": file_content[:5000] if file.type == "text/plain" else ""
                        })
                    
                    except Exception as e:
                        st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Ñ–∞–π–ª–∞ {file.name}: {str(e)}")
            
            st.subheader("–†—É—á–Ω–æ–µ –¥–æ–±–∞–≤–ª–µ–Ω–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤")
            
            # Initialize session state for evidence list
            if 'evidence_list' not in st.session_state:
                st.session_state.evidence_list = [{"type": "", "description": ""}]
            
            # Display evidence items for manual entry
            evidence_list = []
            for i, evidence in enumerate(st.session_state.evidence_list):
                col1, col2 = st.columns([1, 3])
                with col1:
                    evidence_type = st.selectbox(
                        "–¢–∏–ø –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞",
                        options=[
                            "", "–ü–æ–∫–∞–∑–∞–Ω–∏—è —Å–≤–∏–¥–µ—Ç–µ–ª—è", "–ü–æ–∫–∞–∑–∞–Ω–∏—è –ø–æ—Ç–µ—Ä–ø–µ–≤—à–µ–≥–æ", "–ü–æ–∫–∞–∑–∞–Ω–∏—è –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ",
                            "–ó–∞–∫–ª—é—á–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–∞", "–ü—Ä–æ—Ç–æ–∫–æ–ª –æ—Å–º–æ—Ç—Ä–∞", "–ü—Ä–æ—Ç–æ–∫–æ–ª –æ–±—ã—Å–∫–∞", "–ò–Ω–æ–µ"
                        ],
                        key=f"evidence_type_{i}",
                        index=0 if evidence["type"] == "" else ["", "–ü–æ–∫–∞–∑–∞–Ω–∏—è —Å–≤–∏–¥–µ—Ç–µ–ª—è", "–ü–æ–∫–∞–∑–∞–Ω–∏—è –ø–æ—Ç–µ—Ä–ø–µ–≤—à–µ–≥–æ", 
                                                             "–ü–æ–∫–∞–∑–∞–Ω–∏—è –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–≥–æ", "–ó–∞–∫–ª—é—á–µ–Ω–∏–µ —ç–∫—Å–ø–µ—Ä—Ç–∞", 
                                                             "–ü—Ä–æ—Ç–æ–∫–æ–ª –æ—Å–º–æ—Ç—Ä–∞", "–ü—Ä–æ—Ç–æ–∫–æ–ª –æ–±—ã—Å–∫–∞", "–ò–Ω–æ–µ"].index(evidence["type"])
                    )
                
                with col2:
                    evidence_description = st.text_area(
                        "–û–ø–∏—Å–∞–Ω–∏–µ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞",
                        value=evidence["description"],
                        height=100,
                        key=f"evidence_description_{i}"
                    )
                
                evidence_list.append({"type": evidence_type, "description": evidence_description})
            
            # Combine both manual and file-based evidence
            combined_evidence_list = evidence_from_files + evidence_list
            
            # Add/remove evidence buttons
            col1, col2 = st.columns(2)
            with col1:
                if st.form_submit_button("‚ûï –î–æ–±–∞–≤–∏—Ç—å –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ"):
                    st.session_state.evidence_list.append({"type": "", "description": ""})
                    st.rerun()
            
            with col2:
                if len(st.session_state.evidence_list) > 1 and st.form_submit_button("‚ûñ –£–¥–∞–ª–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–µ–µ"):
                    st.session_state.evidence_list.pop()
                    st.rerun()
            
            additional_info = st.text_area(
                "–î–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è",
                height=100,
                help="–£–∫–∞–∂–∏—Ç–µ –ª—é–±—É—é –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é, –∫–æ—Ç–æ—Ä–∞—è –º–æ–∂–µ—Ç –±—ã—Ç—å –ø–æ–ª–µ–∑–Ω–∞ –ø—Ä–∏ —Å–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–∏ –∞–∫—Ç–∞"
            )
            
            submit_button = st.form_submit_button("–°—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞—Ç—å –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–∫—Ç")
        
        if submit_button:
            if not case_number or not crime_description or not suspect_info:
                st.error("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –∑–∞–ø–æ–ª–Ω–∏—Ç—å –Ω–æ–º–µ—Ä –¥–µ–ª–∞, –æ–ø–∏—Å–∞–Ω–∏–µ –ø—Ä–µ—Å—Ç—É–ø–ª–µ–Ω–∏—è –∏ –¥–∞–Ω–Ω—ã–µ –æ –ø–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º–æ–º")
                return
            
            # Validate evidence (from combined list)
            valid_evidence = [e for e in combined_evidence_list if e.get("type") and e.get("description")]
            if not valid_evidence:
                st.error("–ù–µ–æ–±—Ö–æ–¥–∏–º–æ –¥–æ–±–∞–≤–∏—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–æ")
                return
            
            with st.spinner("–§–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–µ –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–∫—Ç–∞..."):
                try:
                    # Analyze file evidence content if available
                    file_evidence_content = ""
                    for evidence in valid_evidence:
                        if evidence.get("fileContent"):
                            file_evidence_content += f"\n–ò–∑ —Ñ–∞–π–ª–∞ '{evidence.get('fileName', '')}':\n{evidence.get('fileContent')}\n"
                    
                    # Add file content to additional info if available
                    enhanced_additional_info = additional_info
                    if file_evidence_content:
                        enhanced_additional_info = (additional_info or "") + "\n\n–°–æ–¥–µ—Ä–∂–∏–º–æ–µ —Ñ–∞–π–ª–æ–≤ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤:\n" + file_evidence_content
                    
                    # Generate indictment
                    indictment_text = generate_indictment(
                        client, 
                        case_number, 
                        crime_description, 
                        suspect_info, 
                        valid_evidence, 
                        enhanced_additional_info
                    )
                    
                    # Analyze evidence
                    evidence_analysis = analyze_evidence(client, valid_evidence, crime_description)
                    
                    # Extract defendant name from suspect info
                    defendant = "–ü–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π"
                    suspect_lines = suspect_info.split('\n')
                    if suspect_lines and ":" in suspect_lines[0]:
                        defendant = suspect_lines[0].split(':')[1].strip()
                    elif len(suspect_lines) > 0:
                        defendant = suspect_lines[0].strip()
                    
                    # Prepare results
                    indictment_results = {
                        "id": case_number,
                        "caseNumber": case_number,
                        "defendant": defendant,
                        "crimeDescription": crime_description,
                        "suspectInfo": suspect_info,
                        "evidenceList": valid_evidence,
                        "additionalInformation": additional_info,
                        "indictmentText": indictment_text,
                        "evidenceAnalysis": evidence_analysis,
                        "generatedDate": datetime.datetime.now().isoformat()
                    }
                    
                    # Parse indictment to extract parts
                    try:
                        parts = indictment_text.split("##")
                        indictment_parts = {}
                        current_part = ""
                        for part in parts:
                            if part.strip():
                                lines = part.strip().split('\n')
                                if lines and lines[0].strip():
                                    part_name = lines[0].strip().lower()
                                    if "–≤–≤–æ–¥–Ω–∞—è" in part_name:
                                        indictment_parts["introductionText"] = '\n'.join(lines[1:]).strip()
                                    elif "–æ–ø–∏—Å–∞—Ç–µ–ª—å–Ω–∞—è" in part_name:
                                        indictment_parts["descriptionText"] = '\n'.join(lines[1:]).strip()
                                    elif "–¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤" in part_name:
                                        indictment_parts["evidenceAnalysisText"] = '\n'.join(lines[1:]).strip()
                                    elif "–∑–∞–∫–ª—é—á–µ–Ω–∏–µ" in part_name or "–∑–∞–∫–ª—é—á–∏—Ç–µ–ª—å–Ω–∞—è" in part_name:
                                        indictment_parts["conclusionText"] = '\n'.join(lines[1:]).strip()
                                    else:
                                        current_part = '\n'.join(lines).strip()
                                else:
                                    current_part = part.strip()
                        
                        indictment_results.update(indictment_parts)
                        
                        # If parts weren't parsed correctly, use the full text
                        if not indictment_parts:
                            indictment_results["introductionText"] = "–°–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç"
                            indictment_results["descriptionText"] = "–°–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç"
                            indictment_results["evidenceAnalysisText"] = "–°–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç"
                            indictment_results["conclusionText"] = "–°–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç"
                    except:
                        indictment_results["introductionText"] = "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ —Ç–µ–∫—Å—Ç–∞"
                        indictment_results["descriptionText"] = "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ —Ç–µ–∫—Å—Ç–∞"
                        indictment_results["evidenceAnalysisText"] = "–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ä–∞–∑–±–æ—Ä–µ —Ç–µ–∫—Å—Ç–∞"
                        indictment_results["conclusionText"] = "–°–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç"
                    
                    # Save results
                    save_history("indictments", indictment_results)
                    
                    # Display results
                    st.success("–û–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–∫—Ç —É—Å–ø–µ—à–Ω–æ —Å—Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω!")
                    
                    st.subheader("–û–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã–π –∞–∫—Ç")
                    st.markdown(indictment_text)
                    
                    st.subheader("–ê–Ω–∞–ª–∏–∑ –¥–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤")
                    st.markdown(evidence_analysis)
                    
                    # Create DOCX document
                    content_sections = []
                    sections_found = False 
                    section_map = {
                        "–í–í–û–î–ù–ê–Ø –ß–ê–°–¢–¨": "introductionText",
                        "–û–ü–ò–°–ê–¢–ï–õ–¨–ù–ê–Ø –ß–ê–°–¢–¨": "descriptionText",
                        "–î–û–ö–ê–ó–ê–¢–ï–õ–¨–°–¢–í–ê": "evidenceAnalysisText",
                        "–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï": "conclusionText"
                    }
                    for heading, key in section_map.items():
                        content = indictment_results.get(key, '')
                        if content and content != "–°–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç":
                            content_sections.append({'heading': heading, 'content': content})
                            sections_found = True
                    if not sections_found:
                        st.warning("–ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞–∑–¥–µ–ª–∏—Ç—å —Ç–µ–∫—Å—Ç –∞–∫—Ç–∞ –Ω–∞ —Å–µ–∫—Ü–∏–∏. DOCX –±—É–¥–µ—Ç —Å–æ–¥–µ—Ä–∂–∞—Ç—å –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç.")
                        content_sections = [{'heading': "", 'content': indictment_text}]
                    
                    # Create metadata
                    metadata = {
                        "–ù–æ–º–µ—Ä –¥–µ–ª–∞": case_number,
                        "–î–∞—Ç–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è": datetime.datetime.now().strftime("%Y-%m-%d"),
                        "–û–±–≤–∏–Ω—è–µ–º—ã–π": defendant
                    }
                    
                    docx_bytes = create_docx_document(
                        "–û–ë–í–ò–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ö–¢",
                        content_sections,
                        metadata
                    )
                    
                    col1, col2, col3 = st.columns(3)
                    
                    with col1:
                        st.download_button(
                            "üìÑ –°–∫–∞—á–∞—Ç—å –∞–∫—Ç (DOCX)",
                            data=docx_bytes,
                            file_name=f"indictment_{case_number}.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            key=f"download_indict_docx_main_{case_number}"
                        )
                    
                    with col2:
                        st.download_button(
                            "üìù –°–∫–∞—á–∞—Ç—å –∞–∫—Ç (—Ç–µ–∫—Å—Ç)",
                            data=indictment_text,
                            file_name=f"indictment_{case_number}.txt",
                            mime="text/plain",
                            key=f"download_indict_txt_main_{case_number}"
                        )
                        
                    with col3:
                        st.download_button(
                            "üìä –°–∫–∞—á–∞—Ç—å –¥–∞–Ω–Ω—ã–µ (JSON)",
                            data=json.dumps(indictment_results, ensure_ascii=False, indent=2),
                            file_name=f"indictment_{case_number}.json",
                            mime="application/json",
                            key=f"download_indict_json_main_{case_number}"
                        )
                    
                except Exception as e:
                    st.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏–∏ –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω–æ–≥–æ –∞–∫—Ç–∞: {str(e)}")
    
    with tab2:
        st.header("–ò—Å—Ç–æ—Ä–∏—è –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∞–∫—Ç–æ–≤")
        
        # Load history
        history = load_history("indictments")
        
        if not history:
            st.info("–ò—Å—Ç–æ—Ä–∏—è –æ–±–≤–∏–Ω–∏—Ç–µ–ª—å–Ω—ã—Ö –∞–∫—Ç–æ–≤ –ø—É—Å—Ç–∞")
        else:
            for item in history:
                with st.expander(f"–î–µ–ª–æ {item.get('caseNumber', 'N/A')} - {item.get('defendant', '–ü–æ–¥—Å—É–¥–∏–º—ã–π')}"):
                    st.write(f"**–î–∞—Ç–∞:** {item.get('generatedDate', 'N/A')[:10]}")
                    
                    # –ó–∞–º–µ–Ω—è–µ–º –≤–ª–æ–∂–µ–Ω–Ω—ã–µ expander –Ω–∞ tabs
                    tab1, tab2, tab3, tab4 = st.tabs(["–û–ø–∏—Å–∞–Ω–∏–µ", "–ü–æ–¥–æ–∑—Ä–µ–≤–∞–µ–º—ã–π", "–î–æ–∫–∞–∑–∞—Ç–µ–ª—å—Å—Ç–≤–∞", "–¢–µ–∫—Å—Ç –∞–∫—Ç–∞"])
                    with tab1: st.write(item.get('crimeDescription', ''))
                    with tab2: st.write(item.get('suspectInfo', ''))
                    with tab3:
                        if isinstance(item.get('evidenceList'), list):
                           for evidence in item.get('evidenceList', []):
                               evidence_text = f"**{evidence.get('type', '')}:** {evidence.get('description', '')}"
                               if evidence.get('fileName'): evidence_text += f" (–§–∞–π–ª: {evidence.get('fileName')})"
                               st.markdown(evidence_text)
                        else: st.write(item.get('evidenceList', ''))
                    with tab4: st.write(item.get('indictmentText', ''))
                    
                    col1, col2, col3 = st.columns(3)
                    with col1:
                        st.download_button(
                            "–°–∫–∞—á–∞—Ç—å –∞–∫—Ç (—Ç–µ–∫—Å—Ç)",
                            data=item.get('indictmentText', ''),
                            file_name=f"indictment_{item.get('caseNumber', 'case')}.txt",
                            mime="text/plain",
                            key=f"download_indict_txt_hist_{item.get('id', '')}"
                        )
                    
                    with col2:
                        # Create DOCX document for download
                        content_sections = []
                        sections_found = False
                        section_map = {
                            "–í–í–û–î–ù–ê–Ø –ß–ê–°–¢–¨": "introductionText",
                            "–û–ü–ò–°–ê–¢–ï–õ–¨–ù–ê–Ø –ß–ê–°–¢–¨": "descriptionText",
                            "–î–û–ö–ê–ó–ê–¢–ï–õ–¨–°–¢–í–ê": "evidenceAnalysisText",
                            "–ó–ê–ö–õ–Æ–ß–ï–ù–ò–ï": "conclusionText"
                        }
                        for heading, key in section_map.items():
                            content = item.get(key, '')
                            if content and content != "–°–º–æ—Ç—Ä–∏—Ç–µ –ø–æ–ª–Ω—ã–π —Ç–µ–∫—Å—Ç":
                                content_sections.append({'heading': heading, 'content': content})
                                sections_found = True
                        if not sections_found:
                            content_sections = [{'heading': "", 'content': item.get('indictmentText', '')}]
                        
                        # Create metadata
                        metadata = {
                            "–ù–æ–º–µ—Ä –¥–µ–ª–∞": item.get('caseNumber', ''),
                            "–î–∞—Ç–∞ —Ñ–æ—Ä–º–∏—Ä–æ–≤–∞–Ω–∏—è": item.get('generatedDate', '')[:10],
                            "–û–±–≤–∏–Ω—è–µ–º—ã–π": item.get('defendant', '')
                        }
                        
                        docx_bytes = create_docx_document(
                            "–û–ë–í–ò–ù–ò–¢–ï–õ–¨–ù–´–ô –ê–ö–¢",
                            content_sections,
                            metadata
                        )
                        
                        st.download_button(
                            "–°–∫–∞—á–∞—Ç—å (DOCX)",
                            data=docx_bytes,
                            file_name=f"indictment_{item.get('caseNumber', '')}.docx",
                            mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document",
                            key=f"download_indict_docx_hist_{item.get('id', '')}"
                        )
                    
                    with col3:
                        if st.button("–£–¥–∞–ª–∏—Ç—å", key=f"delete_indictment_{item.get('id', '')}"):
                            # Implement deletion logic here
                            st.warning("–§—É–Ω–∫—Ü–∏—è —É–¥–∞–ª–µ–Ω–∏—è –±—É–¥–µ—Ç –¥–æ—Å—Ç—É–ø–Ω–∞ –≤ —Å–ª–µ–¥—É—é—â–µ–π –≤–µ—Ä—Å–∏–∏")

if __name__ == "__main__":
    main()
